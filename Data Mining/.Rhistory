data("mtcars")
data("mtcars")
head(mtcars)
#We use a little trick here, c() allows us to combine values
CI <- x.bar + c(-z, z) * (pop.sd/sqrt(n))
x.bar <- 950
mu <- 1000
sample.sd <- 1000
n <- 100
alpha <- 0.05
#Compare the test statistic to the critical value and make a decision
t.stat <- (x.bar - mu)/(sample.sd/sqrt(n))
t.critical <- qt(1-alpha, n-1)
#P-value method
p.EC <- 1 - pt(t.stat, n-1)
x.bar <- 41100
p.bar <- .464
p <- 0.5
n <- 250
prop <- (p.bar - p)/sqrt((p * (1-p))/250)
p.prop <- 2 * pnorm(prop)
x.bar <- 41100
pop.sd <- 4500
conf.level <- 0.95
z <- 1.96
n <- 36
#We use a little trick here, c() allows us to combine values
CI <- x.bar + c(-z, z) * (pop.sd/sqrt(n))
round(CI, 2)
x.bar <- 950
mu <- 1000
sample.sd <- 1000
n <- 100
alpha <- 0.05
#Compare the test statistic to the critical value and make a decision
t.stat <- (x.bar - mu)/(sample.sd/sqrt(n))
t.critical <- qt(1-alpha, n-1)
#P-value method
p.EC <- 1 - pt(t.stat, n-1)
x.bar <- 4
mu <- 0
sample.sd <- 12
n <- 16
alpha <- 0.05
#Compare the test statistic to the critical value and make a decision
t.stat <- (x.bar - mu)/(sample.sd/sqrt(n))
t.critical <- qt(1-alpha, n-1)
#P-value method
p.CO <- 1 - pt(t.stat, n-1)
x.bar <- 4
mu <- 0
sample.sd <- 12
n <- 16
alpha <- 0.05
#Compare the test statistic to the critical value and make a decision
t.stat <- (x.bar - mu)/(sample.sd/sqrt(n))
t.critical <- qt(1-alpha, n-1)
#P-value method
p.CO <- 1 - pt(t.stat, n-1)
p.bar <- .464
p <- 0.5
n <- 250
prop <- (p.bar - p)/sqrt((p * (1-p))/250)
p.prop <- 2 * pnorm(prop)
#Pepsi Cola example
p.bar <- .464
p <- 0.5
n <- 250
prop <- (p.bar - p)/sqrt((p * (1-p))/250)
p.prop <- 2 * pnorm(prop)
x.bar <- 41100
pop.sd <- 4500
conf.level <- 0.95
z <- 1.96
n <- 36
#We use a little trick here, c() allows us to combine values
CI <- x.bar + c(-z, z) * (pop.sd/sqrt(n))
round(CI, 2)
x.bar <- 5000
pop.sd <- 1500
conf.level <- 0.95
z <- 1.959
n <- 179
#We use a little trick here, c() allows us to combine values
CI <- x.bar + c(-z, z) * (pop.sd/sqrt(n))
round(CI, 2)
x.bar <- 5000.0
pop.sd <- 1500.0
conf.level <- 0.95
z <- 1.959
n <- 179.0
#We use a little trick here, c() allows us to combine values
CI <- x.bar + c(-z, z) * (pop.sd/sqrt(n))
round(CI, 2)
x.bar <- 5000.0
pop.sd <- 1500.0
conf.level <- 0.95
z <- 1.959963985
n <- 179.0
#We use a little trick here, c() allows us to combine values
CI <- x.bar + c(-z, z) * (pop.sd/sqrt(n))
round(CI, 2)
x.bar <- 5000.0
pop.sd <- 1500.0
conf.level <- 0.95
z <- 1.959963985
n <- 179.0
#We use a little trick here, c() allows us to combine values
CI <- x.bar + c(-z, z) * (pop.sd/sqrt(n))
round(CI, 2)
x.bar <- 5000.0
pop.sd <- 1500.0
conf.level <- 0.95
z <- 1.959963985
n <- 179.0
#We use a little trick here, c() allows us to combine values
CI <- x.bar + c(-z, z) * (pop.sd/sqrt(n))
round(CI, 3)
x.bar <- 18.2
sample.sd <- 6.3
conf.level <- 0.90
t <- abs(qt(.05/2, 90))
n <- 91
CI <- x.bar + c(-t, t) * sample.sd/sqrt(n)
round(CI, 2)
x.bar <- 18.2
sample.sd <- 6.3
conf.level <- 0.90
t <- abs(qt(.05/2, 90))
n <- 91
CI <- x.bar + c(-t, t) * sample.sd/sqrt(n)
round(CI, 2)
x.bar <- 18.2
sample.sd <- 6.3
conf.level <- 0.90
t <- abs(qt(.10/2, 90))
n <- 91
CI <- x.bar + c(-t, t) * sample.sd/sqrt(n)
round(CI, 2)
x.bar <- 18.2
sample.sd <- 6.3
conf.level <- 0.90
n <- 91
t <- abs(qt(.10/2, (n-1)))
CI <- x.bar + c(-t, t) * sample.sd/sqrt(n)
round(CI, 2)
x.bar <- 18.2
sample.sd <- 6.3
conf.level <- 0.90
alpha <- 1 - conf.level
n <- 91
t <- abs(qt(.10/2, (n-1)))
CI <- x.bar + c(-t, t) * sample.sd/sqrt(n)
round(CI, 2)
x.bar <- 18.2
sample.sd <- 6.3
conf.level <- 0.90
alpha <- 1 - conf.level
n <- 91
t <- abs(qt(alpha/2, (n-1)))
CI <- x.bar + c(-t, t) * sample.sd/sqrt(n)
round(CI, 2)
x.bar <- 5000.0
pop.sd <- 1500.0
conf.level <- 0.95
z <- 1.959963985
n <- 179.0
e <- z * (pop.sd/sqrt(n))
#We use a little trick here, c() allows us to combine values
CI <- x.bar + c(-z, z) * (pop.sd/sqrt(n))
round(CI, 3)
pop.sd <- .15
conf.level <- 0.95
z <- 1.959963985
n <- 300
e <- z * (pop.sd/sqrt(n))
pop.sd <- .15
conf.level <- 0.95
z <- 1.959963985
n <- 300
e <- z * (pop.sd/sqrt(n))
round(e, 3)
x.bar <- 120
pop.sd <- 20
conf.level <- 0.98
z <- 2.326347874
n <- 50
e <- z * (pop.sd/sqrt(n))
round(e, 3)
#We use a little trick here, c() allows us to combine values
CI <- x.bar + c(-z, z) * (pop.sd/sqrt(n))
round(CI, 3)
p.bar <- 14/150
n <- 150
conf.level <- 0.90
alpha <- 1 - conf.level
e <- t * sqrt((p.bar * (1-p.bar))/n)
round(e, 3)
p.bar <- 14/150
n <- 150
conf.level <- 0.95
z <- 1.644853627
e <- z * sqrt((p.bar * (1-p.bar))/n)
round(e, 3)
p.bar <- 14/150
n <- 150
conf.level <- 0.95
z <- 1.644853627
e <- z * sqrt((p.bar * (1-p.bar))/n)
round(e, 4)
p.bar <- 14/150
n <- 150
conf.level <- 0.95
z <- 1.959963985
e <- z * sqrt((p.bar * (1-p.bar))/n)
round(e, 4)
conf.level <- 0.95
z <- 1.959963985
ul <- .51
ll <- .45
e <- (ul - ll) /2
p.bar <- ul - e
n = sqrt(z) * (p.bar(1-p.bar)) / sqrt(e)
conf.level <- 0.95
z <- 1.959963985
ul <- .51
ll <- .45
e <- (ul - ll) /2
p.bar <- ul - e
n = sqrt(z) * (p.bar * (1-p.bar)) / sqrt(e)
conf.level <- 0.95
z <- 1.959963985
ul <- .51
ll <- .45
e <- (ul - ll) /2
p.bar <- ul - e
n = sqrt(z) * (p.bar * (1-p.bar)) / sqrt(e)
round(n,0)
conf.level <- 0.95
z <- 1.959963985
ul <- .51
ll <- .45
e <- (ul - ll) /2
p.bar <- ul - e
n <- sqrt(z) * (p.bar * (1-p.bar)) / sqrt(e)
round(n,0)
conf.level <- 0.95
z <- 1.959963985
ul <- .51
ll <- .45
e <- (ul - ll) /2
p.bar <- ul - e
n <- (sqrt(z) * (p.bar * (1-p.bar))) / sqrt(e)
round(n,0)
conf.level <- 0.95
z <- 1.959963985
ul <- .51
ll <- .45
e <- (ul - ll) /2
p.bar <- ul - e
n <- (z*z) * (p.bar * (1-p.bar))) / (e*e)
round(n,0)
conf.level <- 0.95
z <- 1.959963985
ul <- .51
ll <- .45
e <- (ul - ll) /2
p.bar <- ul - e
n <- (z*z) * (p.bar * (1-p.bar)) / (e*e)
round(n,0)
conf.level <- 0.95
z <- 1.959963985
ul <- .51
ll <- .45
e <- (ul - ll) /2
p.bar <- ul - e
n <- (z*z) * (p.bar * (1-p.bar)) / (e*e)
ceiling(n)
salaries <- read_xlsx("Starting_Salaries.xlsx", sheet = "Data")
t.test(salaries$`Chemical Engineering`, salaries$`Electrical Engineering`)
t.test
library(readxl); library(tidyverse)
install.packages(readxl)
install.packages(tidyverse)
getwd()
install.packages("tidyverse")
install.packages("readxl")
library(readxl); library(tidyverse)
#We'll do both of these as two-tailed tests
#type ?t.test in the Console to get more details on how to run one-tailed test or test a difference other than 0
mileage <- read_xlsx("Mileage.xlsx", sheet = "Data")
t.test(mileage$`Highway Mileage`, mileage$`City Mileage`)
#Install and load the packages needed for this analysis
#install.packages("readxl"); install.packages("tidyverse")
library(readxl); library(tidyverse)
#We'll do both of these as two-tailed tests
#type ?t.test in the Console to get more details on how to run one-tailed test or test a difference other than 0
mileage <- read_xlsx("Mileage.xlsx", sheet = "Data")
t.test(mileage$`Highway Mileage`, mileage$`City Mileage`)
install.packages("readxl"); install.packages("tidyverse")
mileage <- read_xlsx("Mileage.xlsx", sheet = "Data")
install.packages("MASS"); library(MASS)
# 1. Import groceries.csv file
library(arules)
groceries <- read.transactions("groceries.csv", sep = ",")
install.packages("arules")
# 1. Import groceries.csv file
library(arules)
groceries <- read.transactions("groceries.csv", sep = ",")
#In this lab, we will perform a market basket analysis of transactional data
#from a grocery store.Our market basket analysis will utilize the purchase data
#collected from one month of operation at a real-world grocery store. The data contains
#9,835 transactions.
### ------------------------------------------------------------------------------
setwd('C:\\git\\repo\\R\\Data Mining')
groceries <- read.transactions("groceries.csv", sep = ",")
# 2. Understanding of your data.
# Summary of dataset
summary(groceries)
# Inspect the first 5 transactions
inspect(groceries[1:5])
# How many transactions and items in this data?
items(groceries)
# 3. Data exploration
# Examine the relative frequency of items in descending order
sort(itemFrequency(groceries, type="relative"), decreasing = TRUE)
# What are the top 3 most frequent items?
sort(itemFrequency(groceries, type="relative"), decreasing = TRUE)[1:3]
# Examine the absolute frquency of items in descending order
sort(itemFrequency(groceries, type="absolute"), decreasing = TRUE)
# Plot the most frequent 8 items in the descending order of transaction frequency in percentage
itemFrequencyPlot(groceries, type="relative", topN = 8)
# 4. Use the apriori command to generate rules with minimal support = 0.01 and minimal confidence = 0.3 and max length = 2.
groceries_rules <- apriori(groceries, parameter = list(support = 0.01, confidence = 0.3, maxlen=2))
summary(groceries_rules)
# Display all rules sorted by confidence levels.
inspect(sort(groceries_rules, by = "confidence"))
# Display top 5 rules
inspect(sort(groceries_rules, by = "confidence")[1:5])
# 5. Use the apriori command to  generate rules with minimal support = 0.02 and minimal confidence = 0.4 and max length = 3.
groceries_rules2 <- apriori(groceries, parameter = list(support = 0.02, confidence = 0.4, maxlen=3))
summary(groceries_rules2)
# Display top 10 rules for Task 2 sorted by lift.
inspect(sort(groceries_rules2, by = "lift")[1:10])
# Find and display rules containing "other vegetables"
vegetable_rules <- subset(groceries_rules2, items %in% "other vegetables")
inspect(vegetable_rules)
# Find and display rules containing "other vegetables" on the left-hand side
vegetable_rules_l <- subset(groceries_rules2, lhs %in% "other vegetables")
inspect(vegetable_rules_l)
# Find and display rules containing "other vegetables" on the right-hand side
vegetable_rules_r <- subset(groceries_rules2, rhs %in% "other vegetables")
inspect(vegetable_rules_r)
# 6. Use the apriori command to generate about 30 to 50 association rules. Set your own minimum support and confidence threshold levels.
# Remember if the thresholds are too low, you will get too many rules, or if you set them too high, you may not get any or enough rules.
groceries_rules3 <- apriori(groceries, parameter = list(support = 0.02, confidence = 0.3, maxlen=4))
summary(groceries_rules3)
# Inspect all of the rules in the descending lift values of the rules.
inspect(sort(groceries_rules, by = "lift"))
# Select an interesting rule and explain how it can benefit the grocery store.
inspect(sort(groceries_rules, by = "lift"))[1:1]
# Select an interesting rule and explain how it can benefit the grocery store.
inspect(sort(groceries_rules, by = "lift"))[1]
# Inspect all of the rules in the descending lift values of the rules.
inspect(sort(groceries_rules, by = "lift"))
# Select an interesting rule and explain how it can benefit the grocery store.
inspect(sort(groceries_rules, by = "lift")[1])
